Training/evaluation parameters Namespace(adam_epsilon=1e-08, arch='bert', do_data=False, do_lower_case=True, do_test=False, do_train=True, epochs=6, eval_batch_size=8, eval_max_seq_len=256, fp16=False, fp16_opt_level='O1', grad_clip=1.0, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=0, mode='min', monitor='valid_loss', n_gpu='0', predict_checkpoints=0, resume_path='', save_best=True, seed=42, sorted=1, train_batch_size=8, train_max_seq_len=256, valid_size=0.2, warmup_proportion=0.1, weight_decay=0.01)
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/home1/xw176/.cache/torch/pytorch_transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
initializing model
https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpj8gusd3g
copying /tmp/tmpj8gusd3g to cache at /home/home1/xw176/.cache/torch/pytorch_transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.893eae5c77904d1e9175faf98909639d3eb20cc7e13e2be395de9a0d8a0dad52
creating metadata file for /home/home1/xw176/.cache/torch/pytorch_transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.893eae5c77904d1e9175faf98909639d3eb20cc7e13e2be395de9a0d8a0dad52
removing temp file /tmp/tmpj8gusd3g
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/home1/xw176/.cache/torch/pytorch_transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.893eae5c77904d1e9175faf98909639d3eb20cc7e13e2be395de9a0d8a0dad52
Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 645,
  "output_attentions": false,
  "output_hidden_states": false,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 119547
}

https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp588kgwzf
copying /tmp/tmp588kgwzf to cache at /home/home1/xw176/.cache/torch/pytorch_transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
creating metadata file for /home/home1/xw176/.cache/torch/pytorch_transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
removing temp file /tmp/tmp588kgwzf
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/home1/xw176/.cache/torch/pytorch_transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Weights of BertForMultiLable not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
Weights from pretrained model not used in BertForMultiLable: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
initializing callbacks
***** Running training *****
  Num Epochs = 6
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 200000
Warning: There's no GPU available on this machine, training will be performed on CPU.
Warning: The number of GPU's configured to use is 0, but only 0 are available on this machine.
Epoch 1/6
Epoch 1 - summary 1/1746: summary_1779
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/home1/xw176/.cache/torch/pytorch_transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
Saving examples into cached file /home/home1/xw176/work/Bert-Multi-Label-Text-Classification/pybert/dataset/cached/cached_train_examples_1779_bert
*** Example ***
guid: train-0
tokens: [CLS] weg ##werf ##hand ##sch ##uh zum rein ##igen von tier ##en ; dis ##posa ##ble g ##love for clean ##ing pet ##s ; gant jet ##able pour lave ##r des animaux ; a dis ##posa ##ble g ##love for releasing a det ##erg ##ent and / or anti - parasit ##e formula ##tion ##for pet ##s and / or farm animals , which in contact with water generate ##s f ##oa ##m which ##do ##es not need to be subsequently rin ##sed . further ##more , the dry dorsal part ( 17 ' ) of the g ##love may be used to dry the animal after was ##hing , and after ##cle ##anin ##g , the g ##love is removed by being turned inside - out so that dir ##t and ##hair remain within . ; a dis ##posa ##ble g ##love for releasing a det ##erg ##ent and / or anti - parasit ##e formula ##tion ##for pet ##s and / or farm animals , which in contact with water generate ##s f ##oa ##m which ##do ##es not need to be subsequently rin ##sed . further ##more , the dry dorsal part ( 17 ' ) of the g ##love may be used to dry the animal after was ##hing , and after ##cle ##anin ##g , the g ##love is removed by being turned inside - out so that dir ##t and ##hair remain within . ; * * field of the invention * * the present invention relate ##s to [SEP]
input_ids: 101 21437 83332 41137 12044 18593 10580 74720 13741 10166 60704 10136 132 27920 40268 11203 175 73477 10142 55911 10230 32784 10107 132 13191 48504 13096 10322 73304 10129 10139 41161 132 169 27920 40268 11203 175 73477 10142 77027 169 10349 69248 11405 10111 120 10345 14249 118 64130 10112 29659 10822 19706 32784 10107 10111 120 10345 30568 22528 117 10319 10106 20637 10169 12286 74195 10107 174 14783 10147 10319 10317 10171 10472 17367 10114 10347 20961 42840 16219 119 14586 19594 117 10105 36796 51774 10668 113 10273 112 114 10108 10105 175 73477 11387 10347 11031 10114 36796 10105 18882 10662 10134 30809 117 10111 10662 19478 106281 10240 117 10105 175 73477 10124 23898 10155 11223 21031 22978 118 10950 10380 10189 15895 10123 10111 37323 25430 12381 119 132 169 27920 40268 11203 175 73477 10142 77027 169 10349 69248 11405 10111 120 10345 14249 118 64130 10112 29659 10822 19706 32784 10107 10111 120 10345 30568 22528 117 10319 10106 20637 10169 12286 74195 10107 174 14783 10147 10319 10317 10171 10472 17367 10114 10347 20961 42840 16219 119 14586 19594 117 10105 36796 51774 10668 113 10273 112 114 10108 10105 175 73477 11387 10347 11031 10114 36796 10105 18882 10662 10134 30809 117 10111 10662 19478 106281 10240 117 10105 175 73477 10124 23898 10155 11223 21031 22978 118 10950 10380 10189 15895 10123 10111 37323 25430 12381 119 132 115 115 13939 10108 10105 66626 115 115 10105 12254 66626 110205 10107 10114 102
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
guid: train-1
tokens: [CLS] ver ##fahren zum her ##stellen einer rotor ##sch ##auf ##el einer wind ##ener ##gie ##anlage ; methods of making wind turbine rotor blade ##s ; procédé de fabrication des au ##bes pour é ##olie ##nne ; a method of manufacturing a wind turbine rotor blade ( 114 ) includes , in one ##em ##bod ##iment , the steps of providing a core ( 120 ) , and apply ##ing at least one ##rei ##nfo ##rci ##ng skin ( 126 ) to the core to form a blade suba ##ssem ##bly ( 131 ) . each ##rei ##nfo ##rci ##ng skin is formed from a mat of rein ##for ##cing fiber ##s . the method also ##in ##clu ##des apply ##ing a micro - por ##ous membrane ( 128 ) over the at least one ##rei ##nfo ##rci ##ng skin , apply ##ing a va ##cuum film ( 138 ) over the micro - por ##ous membrane , introducing a pol ##ymer ##ic res ##in to the core , in ##fus ##ing the res ##in through the core ##and through the at least one rein ##for ##cing skin by apply ##ing a va ##cuum to the ##blad ##e assembly , and cu ##ring the res ##in to form the rotor blade . ; a method of manufacturing a wind turbine rotor blade ( 114 ) includes , in one ##em ##bod ##iment , the steps of providing a core ( 120 ) , and apply ##ing at least one ##rei ##nfo ##rci ##ng skin ( [SEP]
input_ids: 101 16719 28638 10580 10485 28211 10599 95823 12044 103703 10570 10599 31346 36446 20400 45258 132 27413 10108 14293 31346 78995 95823 93093 10107 132 105633 10104 57515 10139 10257 16216 10322 263 69400 15490 132 169 22414 10108 43615 169 31346 78995 95823 93093 113 16977 114 15433 117 10106 10464 10451 70058 28011 117 10105 50879 10108 26099 169 27362 113 12048 114 117 10111 48515 10230 10160 16298 10464 31510 96176 43774 10376 40564 113 17813 114 10114 10105 27362 10114 12188 169 93093 30156 102130 31748 113 18372 114 119 11948 31510 96176 43774 10376 40564 10124 14629 10188 169 17255 10108 74720 19706 19113 99159 10107 119 10105 22414 10379 10245 78225 10920 48515 10230 169 54396 118 10183 13499 53489 113 16196 114 10491 10105 10160 16298 10464 31510 96176 43774 10376 40564 117 48515 10230 169 10321 94540 10458 113 19462 114 10491 10105 54396 118 10183 13499 53489 117 107063 169 16304 89254 11130 39429 10245 10114 10105 27362 117 10106 55729 10230 10105 39429 10245 11222 10105 27362 14752 11222 10105 10160 16298 10464 74720 19706 19113 40564 10155 48515 10230 169 10321 94540 10114 10105 37538 10112 38946 117 10111 10854 13135 10105 39429 10245 10114 12188 10105 95823 93093 119 132 169 22414 10108 43615 169 31346 78995 95823 93093 113 16977 114 15433 117 10106 10464 10451 70058 28011 117 10105 50879 10108 26099 169 27362 113 12048 114 117 10111 48515 10230 10160 16298 10464 31510 96176 43774 10376 40564 113 102
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Saving features into cached file /home/home1/xw176/work/Bert-Multi-Label-Text-Classification/pybert/dataset/cached/cached_train_features_1779_256_bert
sorted data by th length of input
Loading examples from cached file /home/home1/xw176/work/Bert-Multi-Label-Text-Classification/pybert/dataset/summary_pickle/cached_valid_examples_1779_bert
Loading features from cached file /home/home1/xw176/work/Bert-Multi-Label-Text-Classification/pybert/dataset/summary_pickle/cached_valid_features_1779_256_bert
Epoch 1 - summary 2/1746: summary_2423
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/home1/xw176/.cache/torch/pytorch_transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
Saving examples into cached file /home/home1/xw176/work/Bert-Multi-Label-Text-Classification/pybert/dataset/cached/cached_train_examples_2423_bert
*** Example ***
guid: train-0
tokens: [CLS] ver ##fahren und vor ##richtung zur ra ##uch ##gas ##be ##handlung ; method and app ##arat ##us for fl ##ue gas treatment ; procédé et appareil pour le traitement de gaz combustible ; a method for fl ##ue gas treatment includes causing a com ##bustion in a bo ##iler ( 15 , 19 ) using at least a part of a fl ##ue gas ( 12 ) em ##itted from a gas turbine ( 11 ) and introduced from at least one of an ups ##tream side and a down ##stream side of ##an ex ##haus ##t heat recovery bo ##iler ( 13 ) , which recover ##s a high - temperature heat ##of the fl ##ue gas ( 12 ) , so as to increase a concentration of carbon dio ##xide int ##he fl ##ue gas , and recover ##ing carbon dio ##xide in a carbon dio ##xide recovery ##app ##arat ##us ( 18 ) . ; a method for fl ##ue gas treatment includes causing a com ##bustion in a bo ##iler ( 15 , 19 ) using at least a part of a fl ##ue gas ( 12 ) em ##itted from a gas turbine ( 11 ) and introduced from at least one of an ups ##tream side and a down ##stream side of ##an ex ##haus ##t heat recovery bo ##iler ( 13 ) , which recover ##s a high - temperature heat ##of the fl ##ue gas ( 12 ) , so as to increase a concentration of [SEP]
input_ids: 101 16719 28638 10130 11190 41406 10736 11859 20591 14644 11044 52044 132 22414 10111 72894 49651 10251 10142 58768 12772 16091 21379 132 105633 10131 65347 10322 10141 46824 10104 34055 54811 132 169 22414 10142 58768 12772 16091 21379 15433 34705 169 10212 96641 10106 169 20506 33526 113 10208 117 10270 114 13382 10160 16298 169 10668 10108 169 58768 12772 16091 113 10186 114 10266 107456 10188 169 16091 78995 113 10193 114 10111 17037 10188 10160 16298 10464 10108 10151 107717 90047 12250 10111 169 12935 69190 12250 10108 10206 11419 14465 10123 33955 61958 20506 33526 113 10249 114 117 10319 94962 10107 169 11846 118 23509 33955 20324 10105 58768 12772 16091 113 10186 114 117 10380 10146 10114 20299 169 37524 10108 36915 14283 44186 26391 11643 58768 12772 16091 117 10111 94962 10230 36915 14283 44186 10106 169 36915 14283 44186 61958 102295 49651 10251 113 10218 114 119 132 169 22414 10142 58768 12772 16091 21379 15433 34705 169 10212 96641 10106 169 20506 33526 113 10208 117 10270 114 13382 10160 16298 169 10668 10108 169 58768 12772 16091 113 10186 114 10266 107456 10188 169 16091 78995 113 10193 114 10111 17037 10188 10160 16298 10464 10108 10151 107717 90047 12250 10111 169 12935 69190 12250 10108 10206 11419 14465 10123 33955 61958 20506 33526 113 10249 114 117 10319 94962 10107 169 11846 118 23509 33955 20324 10105 58768 12772 16091 113 10186 114 117 10380 10146 10114 20299 169 37524 10108 102
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
guid: train-1
tokens: [CLS] ver ##fahren zur r ##ück ##ge ##win ##nung von energie aus dem ab ##gas eines br ##enne ##rs ; method for re ##gain ##ing energy from the ex ##haus ##t gas of a bu ##rner ; procédé de r ##éc ##up ##ération d ' énergie à partir du gaz d ' é ##chap ##pe ##ment d ' un br ##û ##leur ; zur dam ##pfer ##zeug ##ung werden br ##enne ##r ( 11 ) eingesetzt , die einen dam ##pf ##kes ##sel ( 10 ) be ##hei ##zen . der br ##enne ##r ( 11 ) erzeugt ab ##gas mit einer ver ##hält ##nis ##mäßig hohen ##tem ##pera ##tur . es ist bekannt , einen teil der energie im he ##i ##ßen ab ##gas des ##bre ##nner ##s ( 11 ) zurück ##zug ##ew ##innen durch vor ##w ##är ##mung der dem br ##enne ##r ( 11 ) zu ##zuführen ##den verb ##ren ##nung ##slu ##ft . danach hat das ab ##gas immer noch eine ##ver ##hält ##nis ##mäßig hohe temperatur von bis zu 120 ##° ##c . die er ##fin ##dung sieht es vor , dem ab ##gas des br ##enne ##rs ( 11 ) zusätzliche energie ##zu ##m vor ##w ##är ##men des sp ##eis ##ew ##asse ##rs für den dam ##pf ##kes ##sel ( 10 ) zu ent ##ziehen . dadurch ##kan ##n auch die rest ##liche energie im ab ##gas des br ##enne ##rs ( 11 ) größtenteils ##zur ##ück ##ge ##won ##nen werden , indem die temperatur des ab [SEP]
input_ids: 101 16719 28638 10736 186 67043 10525 24748 35637 10166 39092 10441 10268 11357 14644 11655 33989 21838 10943 132 22414 10142 11639 85473 10230 18603 10188 10105 11419 14465 10123 16091 10108 169 11499 65730 132 105633 10104 186 102063 14590 51335 172 112 35518 254 11523 10168 34055 172 112 263 31678 11355 10426 172 112 10119 33989 71323 55692 132 10736 39121 69828 95780 10716 10615 33989 21838 10129 113 10193 114 19976 117 10128 10897 39121 55942 21885 12912 113 10150 114 10347 89508 11985 119 10118 33989 21838 10129 113 10193 114 95798 11357 14644 10221 10599 16719 77455 12597 48392 28839 19665 37097 15698 119 10196 10298 14874 117 10897 21185 10118 39092 10211 10261 10116 20284 11357 14644 10139 13724 30021 10107 113 10193 114 14658 21062 26127 35633 10714 11190 10874 19269 49026 10118 10268 33989 21838 10129 113 10193 114 10304 60883 10633 62961 10969 35637 107992 12961 119 22961 11250 10242 11357 14644 15967 11230 10359 12563 77455 12597 48392 31971 71838 10166 10467 10304 12048 12007 10350 119 10128 10163 29359 20458 43823 10196 11190 117 10268 11357 14644 10139 33989 21838 10943 113 10193 114 83904 39092 13078 10147 11190 10874 19269 11418 10139 32650 36776 26127 77923 10943 10307 10140 39121 55942 21885 12912 113 10150 114 10304 61047 53833 119 34133 10706 10115 10515 10128 17333 12337 39092 10211 11357 14644 10139 33989 21838 10943 113 10193 114 93220 63934 67043 10525 36816 11216 10615 117 35417 10128 71838 10139 11357 102
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
