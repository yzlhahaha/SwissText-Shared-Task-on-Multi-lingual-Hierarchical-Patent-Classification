{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|██████████| 7048/7048 [00:00<00:00, 232875.55it/s]\n",
      "100%|██████████| 7048/7048 [00:19<00:00, 369.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "\n",
    "from get_data import load_data_small\n",
    "from extract_features import extract_features\n",
    "#from IPC_parser import *\n",
    "from utils import construct_adjacency_matrix, encode_label_hierarchical, get_all_labels\n",
    "from model import classify\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "class data_set:\n",
    "\tdef __init__(self, X, Y, A):\n",
    "\t\tself.X = X\n",
    "\t\tself.Y = Y\n",
    "\t\tself.A = A\n",
    "\n",
    "\n",
    "def construct_train_test_val_datasets(data, all_labels, A):\n",
    "\tN = len(data)\n",
    "\tindices = list(range(N))\n",
    "\trandom.shuffle(indices)\n",
    "\n",
    "\tX = [data[k]['embedding'] for k in data.keys()]\n",
    "\tX = np.vstack(X)\n",
    "\n",
    "\tY = [data[k]['labels'] for k in data.keys()]\n",
    "\tY = encode_label_hierarchical(Y, all_labels)\n",
    "\n",
    "\n",
    "\ttrain = indices[:int(N*0.5)] # 70% data used for training\n",
    "\ttest = indices[int(N*0.5) : int(N*0.8)] # 20% data used for testing\n",
    "\tval = indices[int(N*0.8):] # 10% data used for validation\n",
    "\n",
    "\ttrain = data_set(X[train, :], Y[train, :], A)\n",
    "\ttest = data_set(X[test, :], Y[test, :], A)\n",
    "\tval = data_set(X[val, :], Y[val, :], A)\n",
    "\n",
    "\treturn train, test, val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labeled_patent_data, unlabeled_patent_data = load_data_small(50000)\n",
    "label_list = [labeled_patent_data[k]['labels'] for k in labeled_patent_data.keys()]\n",
    "sections, classes, subclasses = get_all_labels(label_list) # returns A, B, .. | A01, A02, ..| A01B, A01C, ..\n",
    "data = extract_features(labeled_patent_data, extractor = \"tfidf+glove\", K=300)\n",
    "\n",
    "A = construct_adjacency_matrix(sections, classes, subclasses)\n",
    "\n",
    "all_labels = sections + classes + subclasses\n",
    "train, test, val = construct_train_test_val_datasets(data, all_labels, A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xiahu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/xiahu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/xiahu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3524 samples, validate on 1410 samples\n",
      "Epoch 1/30\n",
      " - 2s - loss: 0.7333 - binary_crossentropy: 0.7331 - val_loss: 0.6549 - val_binary_crossentropy: 0.6547\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.5733 - binary_crossentropy: 0.5731 - val_loss: 0.4717 - val_binary_crossentropy: 0.4715\n",
      "Epoch 3/30\n",
      " - 1s - loss: 0.3898 - binary_crossentropy: 0.3896 - val_loss: 0.2975 - val_binary_crossentropy: 0.2973\n",
      "Epoch 4/30\n",
      " - 1s - loss: 0.2356 - binary_crossentropy: 0.2354 - val_loss: 0.1720 - val_binary_crossentropy: 0.1718\n",
      "Epoch 5/30\n",
      " - 1s - loss: 0.1359 - binary_crossentropy: 0.1357 - val_loss: 0.1046 - val_binary_crossentropy: 0.1044\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.0957 - binary_crossentropy: 0.0955 - val_loss: 0.0839 - val_binary_crossentropy: 0.0837\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.0793 - binary_crossentropy: 0.0792 - val_loss: 0.0701 - val_binary_crossentropy: 0.0699\n",
      "Epoch 8/30\n",
      " - 1s - loss: 0.0645 - binary_crossentropy: 0.0643 - val_loss: 0.0561 - val_binary_crossentropy: 0.0559\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.0551 - binary_crossentropy: 0.0549 - val_loss: 0.0507 - val_binary_crossentropy: 0.0506\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.0502 - binary_crossentropy: 0.0500 - val_loss: 0.0473 - val_binary_crossentropy: 0.0471\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.0471 - binary_crossentropy: 0.0469 - val_loss: 0.0448 - val_binary_crossentropy: 0.0446\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.0452 - binary_crossentropy: 0.0450 - val_loss: 0.0431 - val_binary_crossentropy: 0.0429\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.0434 - binary_crossentropy: 0.0432 - val_loss: 0.0420 - val_binary_crossentropy: 0.0418\n",
      "Epoch 14/30\n",
      " - 1s - loss: 0.0426 - binary_crossentropy: 0.0424 - val_loss: 0.0411 - val_binary_crossentropy: 0.0409\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.0418 - binary_crossentropy: 0.0416 - val_loss: 0.0404 - val_binary_crossentropy: 0.0402\n",
      "Epoch 16/30\n",
      " - 1s - loss: 0.0413 - binary_crossentropy: 0.0411 - val_loss: 0.0399 - val_binary_crossentropy: 0.0397\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.0407 - binary_crossentropy: 0.0405 - val_loss: 0.0393 - val_binary_crossentropy: 0.0391\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.0403 - binary_crossentropy: 0.0401 - val_loss: 0.0390 - val_binary_crossentropy: 0.0388\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.0398 - binary_crossentropy: 0.0396 - val_loss: 0.0387 - val_binary_crossentropy: 0.0385\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.0395 - binary_crossentropy: 0.0393 - val_loss: 0.0383 - val_binary_crossentropy: 0.0381\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.0392 - binary_crossentropy: 0.0390 - val_loss: 0.0380 - val_binary_crossentropy: 0.0378\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.0388 - binary_crossentropy: 0.0387 - val_loss: 0.0378 - val_binary_crossentropy: 0.0376\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.0386 - binary_crossentropy: 0.0384 - val_loss: 0.0376 - val_binary_crossentropy: 0.0374\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.0384 - binary_crossentropy: 0.0382 - val_loss: 0.0374 - val_binary_crossentropy: 0.0372\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.0383 - binary_crossentropy: 0.0381 - val_loss: 0.0373 - val_binary_crossentropy: 0.0371\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.0383 - binary_crossentropy: 0.0381 - val_loss: 0.0371 - val_binary_crossentropy: 0.0369\n",
      "Epoch 27/30\n",
      " - 1s - loss: 0.0380 - binary_crossentropy: 0.0378 - val_loss: 0.0370 - val_binary_crossentropy: 0.0368\n",
      "Epoch 28/30\n",
      " - 1s - loss: 0.0381 - binary_crossentropy: 0.0379 - val_loss: 0.0369 - val_binary_crossentropy: 0.0367\n",
      "Epoch 29/30\n",
      " - 1s - loss: 0.0378 - binary_crossentropy: 0.0376 - val_loss: 0.0368 - val_binary_crossentropy: 0.0366\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.0377 - binary_crossentropy: 0.0375 - val_loss: 0.0367 - val_binary_crossentropy: 0.0365\n",
      "Y_pred [[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "test.Y.sum(0)!=0 [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      " False  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True False False False  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True False False False False  True  True  True  True False  True  True\n",
      " False  True False  True False  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True False\n",
      " False False  True  True  True False  True  True  True  True  True  True\n",
      "  True False  True  True  True  True False  True  True  True False  True\n",
      " False False  True False  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      " False False  True  True  True  True  True  True False  True False False\n",
      "  True  True  True  True  True False  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False False False  True  True  True False  True\n",
      "  True  True  True False  True  True False  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True False  True  True  True  True False  True\n",
      " False  True  True  True  True False  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True False  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True False  True\n",
      "  True  True  True  True False  True  True  True False  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True False  True False  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True False  True  True  True  True  True  True False  True  True\n",
      " False  True False  True  True  True  True  True False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False False False  True] len(test.Y.sum(0)) 635\n",
      "Original:\n",
      "Train:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     average_precision_score 0.16058320931362743\n",
      "     f1_score 0.1867424496194413\n",
      "Test:\n",
      "     average_precision_score 0.18649525713278972\n",
      "     f1_score 0.1872844513853896\n",
      "\n",
      "\n",
      "For case SECTION\n",
      "Training dataset:\n",
      "     average_precision_score 0.1601682287027833\n",
      "     f1_score 0.014465866804171204\n",
      "\n",
      "Testing dataset:\n",
      "     average_precision_score 0.16089058077310645\n",
      "     f1_score 0.019355993035442498\n",
      "\n",
      "\n",
      "For case CLASS\n",
      "Training dataset:\n",
      "     average_precision_score 0.012430260990691154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiahu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/xiahu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     f1_score 0.000754963242719231\n",
      "\n",
      "Testing dataset:\n",
      "     average_precision_score 0.012402311918144742\n",
      "     f1_score 0.0\n",
      "\n",
      "\n",
      "For case SUBCLASS\n",
      "Training dataset:\n",
      "     average_precision_score 0.003366234725375165\n",
      "     f1_score 0.0006365489072506033\n",
      "\n",
      "Testing dataset:\n",
      "     average_precision_score 0.003386832220250458\n",
      "     f1_score 0.0\n"
     ]
    }
   ],
   "source": [
    "results = classify(train, test, val, 30, [len(sections), len(classes), len(subclasses)]) # epoch num = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
